{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw8jdlOD_ezF",
        "outputId": "3f5c1a55-b608-47e6-a7fc-189629af23b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-17 11:07:51--  https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/latest/pose_landmarker_lite.task\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.212.207, 74.125.26.207, 172.217.204.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.212.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5777746 (5.5M) [application/octet-stream]\n",
            "Saving to: ‘pose_landmarker_lite.task’\n",
            "\n",
            "pose_landmarker_lit 100%[===================>]   5.51M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-12-17 11:07:51 (50.6 MB/s) - ‘pose_landmarker_lite.task’ saved [5777746/5777746]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe>=0.10.8  # For new API\n",
        "!wget https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/latest/pose_landmarker_lite.task"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------\n",
        "# CONFIG\n",
        "# ---------------------------\n",
        "VIDEO_PATH = \"/content/Shot2.mp4\"\n",
        "OUTPUT_CSV = \"shot_02_biomech.csv\"\n",
        "OUTPUT_FRAME = \"shot_02_skeleton_frame.jpg\"\n",
        "\n",
        "# ---------------------------\n",
        "# Pose Connections for Drawing\n",
        "# ---------------------------\n",
        "POSE_CONNECTIONS = [\n",
        "    (0, 1), (1, 2), (2, 3), (3, 7), (0, 4), (4, 5), (5, 6), (6, 8),\n",
        "    (9, 10), (11, 12), (11, 13), (13, 15), (15, 17), (15, 19), (15, 21),\n",
        "    (17, 19), (12, 14), (14, 16), (16, 18), (16, 20), (16, 22), (18, 20),\n",
        "    (11, 23), (12, 24), (23, 24), (23, 25), (24, 26), (25, 27), (26, 28),\n",
        "    (27, 29), (28, 30), (29, 31), (30, 32), (27, 31), (28, 32)\n",
        "]\n",
        "\n",
        "# ---------------------------\n",
        "# Draw Landmarks Function\n",
        "# ---------------------------\n",
        "def draw_landmarks(image, landmarks):\n",
        "    \"\"\"Draw pose landmarks and connections on image\"\"\"\n",
        "    h, w, _ = image.shape\n",
        "\n",
        "    # Draw connections\n",
        "    for connection in POSE_CONNECTIONS:\n",
        "        start_idx, end_idx = connection\n",
        "        if start_idx < len(landmarks) and end_idx < len(landmarks):\n",
        "            start = landmarks[start_idx]\n",
        "            end = landmarks[end_idx]\n",
        "\n",
        "            start_point = (int(start.x * w), int(start.y * h))\n",
        "            end_point = (int(end.x * w), int(end.y * h))\n",
        "\n",
        "            cv2.line(image, start_point, end_point, (0, 255, 0), 2)\n",
        "\n",
        "    # Draw landmarks\n",
        "    for lm in landmarks:\n",
        "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "        cv2.circle(image, (cx, cy), 5, (0, 0, 255), -1)\n",
        "        cv2.circle(image, (cx, cy), 7, (255, 255, 255), 2)\n",
        "\n",
        "    return image\n",
        "\n",
        "# ---------------------------\n",
        "# MediaPipe Setup (New API)\n",
        "# ---------------------------\n",
        "base_options = python.BaseOptions(model_asset_path='pose_landmarker_lite.task')\n",
        "options = vision.PoseLandmarkerOptions(\n",
        "    base_options=base_options,\n",
        "    output_segmentation_masks=False,\n",
        "    min_pose_detection_confidence=0.5,\n",
        "    min_pose_presence_confidence=0.5,\n",
        "    min_tracking_confidence=0.5\n",
        ")\n",
        "\n",
        "detector = vision.PoseLandmarker.create_from_options(options)\n",
        "\n",
        "# ---------------------------\n",
        "# Video Load\n",
        "# ---------------------------\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "data = []\n",
        "frame_id = 0\n",
        "saved_overlay = False\n",
        "\n",
        "print(\"Processing video...\")\n",
        "\n",
        "# ---------------------------\n",
        "# Process Video\n",
        "# ---------------------------\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_id += 1\n",
        "\n",
        "    # Convert to MediaPipe Image format\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)\n",
        "\n",
        "    # Detect pose\n",
        "    detection_result = detector.detect(mp_image)\n",
        "\n",
        "    if detection_result.pose_landmarks:\n",
        "        pose_landmarks = detection_result.pose_landmarks[0]  # First person\n",
        "\n",
        "        row = {\"frame\": frame_id}\n",
        "\n",
        "        for idx, lm in enumerate(pose_landmarks):\n",
        "            row[f\"lm_{idx}_x\"] = lm.x\n",
        "            row[f\"lm_{idx}_y\"] = lm.y\n",
        "            row[f\"lm_{idx}_z\"] = lm.z\n",
        "            row[f\"lm_{idx}_visibility\"] = lm.visibility\n",
        "\n",
        "        data.append(row)\n",
        "\n",
        "        # Save one skeleton overlay frame\n",
        "        if not saved_overlay:\n",
        "            annotated_frame = frame.copy()\n",
        "            annotated_frame = draw_landmarks(annotated_frame, pose_landmarks)\n",
        "            cv2.imwrite(OUTPUT_FRAME, annotated_frame)\n",
        "            saved_overlay = True\n",
        "            print(f\"Saved overlay frame at frame {frame_id}\")\n",
        "\n",
        "    # Progress indicator\n",
        "    if frame_id % 30 == 0:\n",
        "        print(f\"Processed {frame_id} frames...\")\n",
        "\n",
        "cap.release()\n",
        "detector.close()\n",
        "\n",
        "# ---------------------------\n",
        "# Save CSV\n",
        "# ---------------------------\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(OUTPUT_CSV, index=False)\n",
        "\n",
        "print(\"\\n✅ Pose extraction complete\")\n",
        "print(f\"Saved: {OUTPUT_CSV}\")\n",
        "print(f\"Saved overlay frame: {OUTPUT_FRAME}\")\n",
        "print(f\"Total frames processed: {frame_id}\")\n",
        "print(f\"Frames with pose detected: {len(data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur2PQA7Q_toP",
        "outputId": "c090fac9-948d-4f69-f9ba-be3cb94cd4b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video...\n",
            "Saved overlay frame at frame 1\n",
            "Processed 30 frames...\n",
            "Processed 60 frames...\n",
            "Processed 90 frames...\n",
            "\n",
            "✅ Pose extraction complete\n",
            "Saved: shot_02_biomech.csv\n",
            "Saved overlay frame: shot_02_skeleton_frame.jpg\n",
            "Total frames processed: 98\n",
            "Frames with pose detected: 98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHgEy-hW_t1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwcRZQ_X_t9o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}